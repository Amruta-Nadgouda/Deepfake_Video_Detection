{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtnZQkTu6tX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81404a8b-6520-4140-9927-58c01abbe017"
      },
      "source": [
        "#loading the google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4r397Dhgmd8"
      },
      "source": [
        "!pip3 install face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f40EeRuvAkO"
      },
      "source": [
        "#Making the list of path of videos from the folder we are using.\n",
        "#Using glob library to make a list of videopaths.\n",
        "\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import copy\n",
        "\n",
        "list_videos =  glob.glob('/content/drive/MyDrive/Deepfake_Amruta_Kirti_CNN_LSTM_tryouts/Dataset/kaggle/train_sample_videos/*.mp4')\n",
        "\n",
        "print(len(list_videos))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzIjA4fwwpvo"
      },
      "source": [
        "#saving the local variables in a file.\n",
        "#the program can be continued from a point even after colab times one out\n",
        "\n",
        "with open('/content/gdrive/MyDrive/Deepfake_Amruta_Kirti_CNN_LSTM_tryouts/Dataset/kaggle/train_sample_videos/video_files.txt','w') as file:\n",
        "  for video_file in list_videos:\n",
        "    \n",
        "    file.write('%s\\n'%video_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bot1iwF8wkM5"
      },
      "source": [
        "#the file is loaded from the video and the \n",
        "\n",
        "with open('/content/gdrive/MyDrive/Deepfake_Amruta_Kirti_CNN_LSTM_tryouts/Dataset/kaggle/train_sample_videos/video_files.txt') as file:\n",
        "  list_videos = file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbjzrvfBelgV"
      },
      "source": [
        "#counting the number of frames in the videos\n",
        "#Only videos having framecount greater then 150 in total are kept.\n",
        "#videos lesser than 150 frames are too short to be processed upon.\n",
        "#therefore the videos whith less then 150 frames are deleted.\n",
        "\n",
        "count_of_frames = []\n",
        "for video in list_videos:\n",
        "  cap = cv2.VideoCapture(video)\n",
        "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
        "    list_videos.remove(video)\n",
        "    continue\n",
        "  count_of_frames.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql4RCGy5emL6"
      },
      "source": [
        "#Displaying all the frame count of all videos in the folder,\n",
        "#displaying the count of videos that are kept out and the ones having greater then 150 are counted\n",
        "#finally displaying what is the mean count of the frames are retained in the list of videos\n",
        "\n",
        "print(\"frames\" , count_of_frames)\n",
        "print(\"Total number of videos: \" , len(count_of_frames))\n",
        "print('Average frame per video:',np.mean(count_of_frames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyVNsQuQ9o42"
      },
      "source": [
        "print('/content/drive/MyDrive/Deepfake_Amruta_Kirti_CNN_LSTM_tryouts/FF_REAL_Face_only_data/aagfhgtpmv.mp4'.format)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8A3amFVeuil"
      },
      "source": [
        "!mkdir '/content/drive/My Drive/Deepfake_Amruta_Kirti_CNN_LSTM_tryouts/kaggle_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U92Ovn3JvV52"
      },
      "source": [
        "def frame_extract(path):\n",
        "  s_shot_of_video = cv2.VideoCapture(path) \n",
        "  success = 1\n",
        "  while success:\n",
        "      truth, image = s_shot_of_video.read()\n",
        "      if truth:\n",
        "          yield image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition\n",
        "from tqdm.autonotebook import tqdm\n",
        "# process the frames\n",
        "def make_cropped_face_videos(path_list,out_dir):\n",
        "  preprocessed_videos =  glob.glob(out_dir+'*.mp4')\n",
        "  print(\"No of videos already present \" , len(preprocessed_videos))\n",
        "  for path in tqdm(path_list):\n",
        "    path_of_video = os.path.join(out_dir,path.split('/')[-1])\n",
        "    if_file_exists = glob.glob(path_of_video)\n",
        "    if(len(if_file_exists) != 0):\n",
        "      print(\"File Already exists: \" , path_of_video)\n",
        "      continue\n",
        "    frames = []\n",
        "    check_flag = 0\n",
        "    crop_video = cv2.VideoWriter(path_of_video,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
        "    print(crop_video.__sizeof__())\n",
        "    for count,frame in enumerate(frame_extract(path)):\n",
        "      if(count <= 150):\n",
        "        frames.append(frame)\n",
        "        if(len(frames) == 4):\n",
        "          faces = face_recognition.batch_face_locations(frames)\n",
        "          for i,face in enumerate(faces):\n",
        "            # print(i,face)\n",
        "            if(len(face) != 0):\n",
        "              corner1,corner2,corner3,corner4 = face[0]\n",
        "            try:\n",
        "              crop_video.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
        "            except:\n",
        "              pass\n",
        "          frames = []\n",
        "    try:\n",
        "      del corner1,corner2,corner3,corner4\n",
        "    except:\n",
        "      pass\n",
        "    crop_video.release()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF5qiWGLvei-"
      },
      "source": [
        "make_cropped_face_videos(list_videos,'/content/drive/My Drive/Deepfake_Amruta_Kirti_CNN_LSTM_tryouts/kaggle_data')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}